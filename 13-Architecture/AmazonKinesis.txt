# Document explaining the components and architecture of Amazon Kinesis service

- Amazon Kinesis was designed to address the complexity and cost of streaming data
  into AWS cloud.
- Kinesis makes it to easy to collect, process and analyze data from various data
  streams such as Event logs, IoT devices, Social media feeds, Click stream data,
  Application data in real time or near time.
- Kinesis contains four services such as Video Streams, Data Streams, Data Firehose
  and Data Analytics.
- Amazon Kinesis Video Stream is used to do stream processing on binary encoded data
  such as audio and video.
- Amazon Kineses Data Stream, Kinesis Data Firehose and Kenisis Data Analytics is
  used to do stream processing on base64 encoded data such as logs, click stream
  data, social media feeds, financial transactions, in-game player activity, geospatial
  services and telemetry from IoT devices.



Layers of Streaming:
- There are 5 layers of streaming.

Source:
  - Mobile Device
  - Metering
  - Click Streams
  - IoT sensors
  - logs

Stream Ingestion:
  The data for streaming can be injested using following services/tools
  - Amazon Kinesis Agent
  - Amazon Kinesis Producer Library
  - Amazon SDK

Stream Storage:
  The data which is stored in this layer is done by Amazon Kinesis Data Streams which
  is called as Producer.
 - Inside Kinesis Data Streams, data can be stored but it cannot be modified. Hence,
   the data is immutable. However, the data can expire.
 - As of today, the Kinesis Data Stream can store data starting from 24 hours upto 365 days.
 - It is a high speed storage buffer.

Stream Processing:
  The Stream Processing layer is managed by the Consumers.
  - Amazon Kinesis Data Analytics
  - Amazon Kineses Consumer Library
  - Amazon Kineses Data Firehose

Destination:
  Consumers send data to the destination layer which can be one of the following
  - Amazon S3
  - Amazon Redshift
  - Amazon Elasticsearch service
  - Splunk

Amazon Kineses Video Stream:
- Designed to stream binary encoded data into AWS from millions of sources (audio
  and video but it can be any binary-encoded time series data)

Amazon Kineses Data Stream:
- A highly customizable data streaming solution available from AWS.
- Highly customizable: All parts involved with stream processing - data ingestion,
  monitoring, scaling, elasticity and consumption are done programmatically when
  creating a stream.
- AWS will provision resources when requested.
- Does not have the ability to Auto scaling.
- To facilitate the development, management and usage of data stream, AWS provides
  APIs, AWS SDKs, AWS CLI, Kinesis agent for Windows and Linux.
- Producers put data records into Kinesis Data Stream.
- Producer can be created using SDKs, APIs or Kinesis Producer Library.
- Each Shard can give 1MBPS or 1000 messages per second.
- A Kinesis Data Stream is a set of shards. A shard contains a sequence of data records.
- Data Records are composed of a sequence number, a Partition key and a Data Blob
  and they are stored as a immutable sequence of bytes.
- Consumers - Amazon Kineses Data Stream Applications get records from Kinesis Data
  stream and process them.
- Consumers can be created using SDKs, APIs or Kinesis Client Library.
- For consumers, in shared consumption - 2 MB/s per shard for all consumers.
- In enhanced consumption - 2MB/s per shard per consumer.
- Once data is entered into Kinesis, it cant be deleted.
- Data storage from 1 to 365 days.
- Supports replay capability.

- There are two types of Consumers:
  - Classic:
    - Pulls data from the stream.
    - Also known as Polling mechanism.
    - There is a limit to number of times and amount of data, consumers can pull from the shard.
  - Enhanced Fan-Out:
    - Push Method: Consumer can subscribe to a shard.
    - Results in data being pushed from the shard into a consumer application.
    - Since polling is removed, Shard limits are removed, every consumer gets provisioned
      throughput of 2 MBs per second per shard.
Capacity Modes:
  - Provisioned Mode:
    - You choose the number of shards provisioned, scale manually or using API.
    - You pay per shard provisioned per hour.
  On demand Mode:
    - No need to manage or provision the capacity.
    - Default capacity of 4 MB/s or 4000 messages/second
    - Scales automatically based on observed throughput peak of last 30 days.
    - Pay per stream per hour and data in/out in GB.

Amazon Kinesis Data Firehose:
- Data Firehose being fully managed is a streaming delivery service for data.
- Ingested data can be dynamically transformed, scaled automatically and can be
  automatically delivered to a data store.
- Not a streaming storage layer in the way that Data stream is.
- It uses Producers to load data into streams in batches and once inside a stream, it
  delivers data into a data store.
- Unlike Data Streams, Data Firehose buffers incoming streaming data before delivering
  data to its destination. The buffer size and buffer interval is chosen when creating
  delivery stream.
- The buffer size is in megabytes and the ranges can vary depending upon the destination.
- The buffer size has to be a minimum of 32MB in size and maximum of 128MB.
- The buffer interval can vary between 60 seconds to 900 seconds.
- Essentially, data buffers inside the stream and it leaves the buffer either when it
  size is full or when buffer interval expires. For this reason, Kinesis Data Firehose
  is considered as a near real-time streaming solution.
- Kinesis Data Firehose can deliver data to four data stores - Amazon S3, Amazon Redshift,
  Amazon Elasticsearch and Splunk. Now, it can also deliver data using generic HTTP
  endpoints and 3rd party solution providers such as MongoDB, DataDog, New Relic.
- Automatic Scaling is possible in Data Firehose.
- It can also transform incoming data from JSON format to Apache Parquet or Apache ORC.
- Parquet and ORC are columnar data formats that save space and has faster queries
  compared to row-oriented data format like JSON.
- It can also invoke Lambda functions to transform incoming source data and deliver
  the transformed data to its destination.
- There is no Free tier for using Kinesis Data Firehose. Costs are only incurred when
  data is inside a Firehose stream. There is no bill for provisioned capacity, but only
  billed for used capacity.
- Doesn't support replay capability.

Amazon Kinesis Data Analytics:
- Kinesis Data Analytics has the ability to read the data from stream in real-time
  and perform aggregation and analysis while data is in motion.
- It does this by leveraging SQL queries, or with Apache Flink using Java or Scala
  to perform time-series analytics, feed real time dashboards and create real-time
  metrics.
- When using Data Firehose with Data Analytics, data can only be queried using SQL.
- Apache Flink with Java or Scala are only available for Kinesis Data Streams.
